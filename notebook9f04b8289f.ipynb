{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2231927,"sourceType":"datasetVersion","datasetId":1340873}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.manifold import TSNE\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation, NMF\nfrom sklearn.metrics import f1_score, accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SpatialDropout1D, Conv1D, GlobalMaxPooling1D, Dense, Dropout, LSTM, Bidirectional\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nimport warnings\nimport nltk\nfrom gensim.models import Word2Vec\nfrom nltk.tokenize import word_tokenize\nwarnings.filterwarnings(action='ignore')\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T20:23:37.638700Z","iopub.execute_input":"2024-04-28T20:23:37.639213Z","iopub.status.idle":"2024-04-28T20:23:37.652182Z","shell.execute_reply.started":"2024-04-28T20:23:37.639179Z","shell.execute_reply":"2024-04-28T20:23:37.650945Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data_path = pd.read_csv('/kaggle/input/twitter-sentiment-dataset/Twitter_Data.csv')\ndf = data_path\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:23:37.654259Z","iopub.execute_input":"2024-04-28T20:23:37.655016Z","iopub.status.idle":"2024-04-28T20:23:38.119700Z","shell.execute_reply.started":"2024-04-28T20:23:37.654974Z","shell.execute_reply":"2024-04-28T20:23:38.118404Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"                                               clean_text  category\n0       when modi promised â€œminimum government maximum...      -1.0\n1       talk all the nonsense and continue all the dra...       0.0\n2       what did just say vote for modi  welcome bjp t...       1.0\n3       asking his supporters prefix chowkidar their n...       1.0\n4       answer who among these the most powerful world...       1.0\n...                                                   ...       ...\n162975  why these 456 crores paid neerav modi not reco...      -1.0\n162976  dear rss terrorist payal gawar what about modi...      -1.0\n162977  did you cover her interaction forum where she ...       0.0\n162978  there big project came into india modi dream p...       0.0\n162979  have you ever listen about like gurukul where ...       1.0\n\n[162980 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df['clean_text'].fillna('', inplace=True)\nall_tweets = ' '.join(df['clean_text'])\n# Tokenize words\ntokenized_text = [word_tokenize(text.lower()) for text in df['clean_text']]\n\n# Word2Vec model\nmodel = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n\n# Most similar words\nsimilar_words = model.wv.most_similar('happy', topn=5)\n\n# Define input and target variables\nX = df['clean_text']\ny = df['category']\n\n# Encode target variable\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\ny = utils.to_categorical(y)\n\n# Tokenize text\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\n\n# Vocabulary size\nvocab_size = len(tokenizer.word_index) + 1\n\n# Max sequence length\nmax_seq_length = max([len(seq) for seq in sequences])\n\n# Pad sequences\nX_pad = pad_sequences(sequences, maxlen=max_seq_length)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:23:38.121235Z","iopub.execute_input":"2024-04-28T20:23:38.121646Z","iopub.status.idle":"2024-04-28T20:24:59.842428Z","shell.execute_reply.started":"2024-04-28T20:23:38.121616Z","shell.execute_reply":"2024-04-28T20:24:59.841543Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers, backend as K, initializers\nfrom keras import backend as K\nfrom keras.layers import Layer\n\ndef squash(x, axis=-1):\n    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n    scale = K.sqrt(s_squared_norm + K.epsilon())\n    return x / scale\n\nclass CapsuleLayer(Layer):\n    def __init__(self, num_capsule, dim_capsule, routings=3, **kwargs):\n        super(CapsuleLayer, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n\n    def build(self, input_shape):\n        self.W = self.add_weight(name='capsule_kernel', \n                                 shape=(input_shape[1], self.num_capsule * self.dim_capsule),\n                                 initializer='glorot_uniform',\n                                 trainable=True)\n\n    def call(self, inputs):\n        inputs_expand = K.expand_dims(inputs, 1)\n        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W), elems=inputs_tiled)\n        inputs_hat = K.reshape(inputs_hat, (-1, inputs.shape[1], self.num_capsule, self.dim_capsule))\n\n        b = K.zeros_like(inputs_hat[:, :, :, 0])  # Shape [batch, input_length, num_capsule]\n\n        for i in range(self.routings):\n            c = K.softmax(b, axis=-1)\n            c_expand = K.expand_dims(c, -1)\n            c_tiled = K.tile(c_expand, [1, 1, 1, self.dim_capsule])\n            outputs = squash(K.sum(c_tiled * inputs_hat, axis=2))  # Sum across the input_length axis\n            if i < self.routings - 1:\n                b += K.sum(inputs_hat * K.expand_dims(outputs, 2), axis=-1)\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return (None, input_shape[1], self.num_capsule, self.dim_capsule)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:24:59.844518Z","iopub.execute_input":"2024-04-28T20:24:59.845154Z","iopub.status.idle":"2024-04-28T20:24:59.860947Z","shell.execute_reply.started":"2024-04-28T20:24:59.845121Z","shell.execute_reply":"2024-04-28T20:24:59.859761Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"vocab_size = 20000  # example vocab size\nmax_seq_length = 500  # e\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, output_dim=100, input_shape=(max_seq_length,)))\nmodel.add(SpatialDropout1D(0.5))\nmodel.add(Bidirectional(LSTM(units=128, dropout=0.5, recurrent_dropout=0.5, return_sequences=True)))\nmodel.add(CapsuleLayer(num_capsule=10,dim_capsule=16,routings=3))\nmodel.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=4, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:24:59.862644Z","iopub.execute_input":"2024-04-28T20:24:59.863126Z","iopub.status.idle":"2024-04-28T20:25:00.356702Z","shell.execute_reply.started":"2024-04-28T20:24:59.863088Z","shell.execute_reply":"2024-04-28T20:25:00.355205Z"},"trusted":true},"execution_count":28,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Bidirectional(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, recurrent_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)))\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(CapsuleLayer(num_capsule\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,dim_capsule\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,routings\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(GlobalMaxPooling1D())\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/sequential.py:120\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/sequential.py:139\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    138\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:222\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m--> 222\u001b[0m         \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/sequential.py:180\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation_utils.py:184\u001b[0m, in \u001b[0;36mcompute_conv_output_shape\u001b[0;34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m    182\u001b[0m     kernel_shape \u001b[38;5;241m=\u001b[39m kernel_size \u001b[38;5;241m+\u001b[39m (input_shape[\u001b[38;5;241m1\u001b[39m], filters)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kernel_shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_shape):\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel shape must have the same length as input, but received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dilation_rate, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    190\u001b[0m     dilation_rate \u001b[38;5;241m=\u001b[39m (dilation_rate,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(spatial_shape)\n","\u001b[0;31mValueError\u001b[0m: Kernel shape must have the same length as input, but received kernel of shape (3, 16, 64) and input of shape (None, 500, 10, 16)."],"ename":"ValueError","evalue":"Kernel shape must have the same length as input, but received kernel of shape (3, 16, 64) and input of shape (None, 500, 10, 16).","output_type":"error"}]},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\nhistory = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=0.1, callbacks=[reduce_lr, early_stop])","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:25:00.357690Z","iopub.status.idle":"2024-04-28T20:25:00.358120Z","shell.execute_reply.started":"2024-04-28T20:25:00.357919Z","shell.execute_reply":"2024-04-28T20:25:00.357937Z"},"trusted":true},"execution_count":null,"outputs":[]}]}